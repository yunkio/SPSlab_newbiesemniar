{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdac1fb8-c454-412e-8b8f-f7fdccb7a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.legacy import data, datasets\n",
    "from torchsummaryX import summary\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ebd89c-f978-4a2b-9aa1-9c55c5428db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "lr = 0.001\n",
    "epochs = 40\n",
    "train_history = []\n",
    "val_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available else \"cpu\")\n",
    "text = data.Field(sequential = True, batch_first = True, lower = True)\n",
    "label = data.Field(sequential = False, batch_first = True)\n",
    "\n",
    "# batch_first : 배치 크기를 첫번째 차원으로 해서 (배치 크기, 문장의 길이) 차원이 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b138e548-75aa-45d7-af30-18af368e2cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequential': True,\n",
       " 'use_vocab': True,\n",
       " 'init_token': None,\n",
       " 'eos_token': None,\n",
       " 'unk_token': '<unk>',\n",
       " 'fix_length': None,\n",
       " 'dtype': torch.int64,\n",
       " 'preprocessing': None,\n",
       " 'postprocessing': None,\n",
       " 'lower': True,\n",
       " 'tokenizer_args': (None, 'en'),\n",
       " 'tokenize': <function torchtext.data.utils._split_tokenizer(x)>,\n",
       " 'include_lengths': False,\n",
       " 'batch_first': True,\n",
       " 'pad_token': '<pad>',\n",
       " 'pad_first': False,\n",
       " 'truncate_first': False,\n",
       " 'stop_words': None,\n",
       " 'is_target': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4542d697-874f-4e59-873a-6a6e12cd4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = datasets.IMDB.splits(text, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb3c8cd-75c1-4f00-9d54-2665b0215c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'label'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(trainset.examples[0]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93ec5504-5f39-41f5-a35c-f630b0a5436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the']\n",
      "pos\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(trainset.examples[0].text[0:10])\n",
    "print(trainset.examples[0].label)\n",
    "print(trainset.examples[1].label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ee93018-5964-4e55-b68c-36fda79d70da",
   "metadata": {},
   "outputs": [],
   "source": [
    "text.build_vocab(trainset, min_freq = 5)\n",
    "label.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0907c6d-a7df-4980-9e1d-66185e4c0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio=0.8)\n",
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((trainset, valset, testset), batch_size=batch_size, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d0d039-ce5e-4dad-8c40-a460b085d264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 973])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_iter)).text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c45df1d1-5aff-41aa-b495-c1adbcf4c11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train]: 20000 [Val]: 5000 [Test]: 25000 [Vocab] 46159 [Classes] 2\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(text.vocab)\n",
    "n_classes = 2\n",
    "print(\"[Train]: %d [Val]: %d [Test]: %d [Vocab] %d [Classes] %d\" %\n",
    "     (len(trainset), len(valset), len(testset), vocab_size, n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecad0618-b046-4120-aff0-d9cc4be762e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGRU(nn.Module):\n",
    "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
    "        super(BasicGRU, self).__init__()\n",
    "        print(\"Building Basic GRU model...\")\n",
    "        self.n_layers = n_layers\n",
    "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embed_dim, self.hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        h_0 = self._init_state(batch_size=x.size(0))\n",
    "        x, _ = self.gru(x, h_0)\n",
    "        h_t = x[:,-1,:]\n",
    "        self.dropout(h_t)\n",
    "        logit = self.out(h_t)\n",
    "        return logit\n",
    "    \n",
    "    def _init_state(self, batch_size=1):\n",
    "        weight = next(self.parameters()).data\n",
    "        return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fb00253-740a-4161-9867-25393dd5ebf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_iter):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(device), batch.label.to(device)\n",
    "        y.data.sub_(1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= (len(train_iter))\n",
    "    train_history.append(train_loss) # 기록 저장\n",
    "    print('Train [{}] \\t Loss: {: .6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cab7a41-66e6-4ccc-bbf6-e1692823711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(device), batch.label.to(device)\n",
    "        y.data.sub_(1)\n",
    "        logit = model(x)\n",
    "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    \n",
    "    val_history.append(avg_loss) # 기록 저장\n",
    "    val_acc_history.append(avg_accuracy.item())\n",
    "\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4ca0750-2496-4f76-84ef-6cde4fadcf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n",
      "===============================================================\n",
      "           Kernel Shape      Output Shape     Params  Mult-Adds\n",
      "Layer                                                          \n",
      "0_embed    [128, 46159]  [128, 1001, 128]  5.908352M  5.908352M\n",
      "1_gru                 -  [128, 1001, 128]    99.072k    98.304k\n",
      "2_dropout             -        [128, 128]          -          -\n",
      "3_out          [128, 2]          [128, 2]      258.0      256.0\n",
      "---------------------------------------------------------------\n",
      "                         Totals\n",
      "Total params          6.007682M\n",
      "Trainable params      6.007682M\n",
      "Non-trainable params        0.0\n",
      "Mult-Adds             6.006912M\n",
      "===============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kernel Shape</th>\n",
       "      <th>Output Shape</th>\n",
       "      <th>Params</th>\n",
       "      <th>Mult-Adds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Layer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_embed</th>\n",
       "      <td>[128, 46159]</td>\n",
       "      <td>[128, 1001, 128]</td>\n",
       "      <td>5908352.0</td>\n",
       "      <td>5908352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_gru</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 1001, 128]</td>\n",
       "      <td>99072.0</td>\n",
       "      <td>98304.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_dropout</th>\n",
       "      <td>-</td>\n",
       "      <td>[128, 128]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_out</th>\n",
       "      <td>[128, 2]</td>\n",
       "      <td>[128, 2]</td>\n",
       "      <td>258.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Kernel Shape      Output Shape     Params  Mult-Adds\n",
       "Layer                                                          \n",
       "0_embed    [128, 46159]  [128, 1001, 128]  5908352.0  5908352.0\n",
       "1_gru                 -  [128, 1001, 128]    99072.0    98304.0\n",
       "2_dropout             -        [128, 128]        NaN        NaN\n",
       "3_out          [128, 2]          [128, 2]      258.0      256.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.zeros((128, 1001), dtype=torch.long) # [length, batch_size]\n",
    "summary(BasicGRU(1, 128, vocab_size, 128, n_classes, 0.25).to(\"cpu\"), inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bd46b49-0bf9-407f-adb0-9e61330f0c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Basic GRU model...\n"
     ]
    }
   ],
   "source": [
    "model = BasicGRU(1, 256, vocab_size, 128, n_classes, 0.5).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88604dad-eec1-4f42-b8a2-fc25035abbc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b956ab51194779ae42ec77e4af07fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train [1] \t Loss:  0.700016\n",
      "Train [2] \t Loss:  0.694708\n",
      "Train [3] \t Loss:  0.694392\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    train(model, optimizer, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print('Val [{}] \\t Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch, val_loss, val_accuracy))\n",
    "    \n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), './snapshot/txtclassfication.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc1208-6929-4f29-9db7-d88092554224",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./snapshot/txtclassfication.pt'))\n",
    "val_loss, val_acc = evaluate(model, test_iter)\n",
    "print('Test loss: %5.2f | Test accuracy: %5.2f' % (val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abb633-9028-4a99-90e4-6a102a26447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(train_history, 'y', label='train loss')\n",
    "loss_ax.plot(val_history, 'r', label='val loss')\n",
    "\n",
    "acc_ax.plot(val_acc_history, 'g', label='val acc')\n",
    "\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "acc_ax.set_ylabel('accuray')\n",
    "\n",
    "loss_ax.legend(loc='upper left')\n",
    "acc_ax.legend(loc='lower left')\n",
    "\n",
    "loss_ax.set_xlim([0,199])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3e46d1-1eb3-49b2-b91b-905483de4760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
